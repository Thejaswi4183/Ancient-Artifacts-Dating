{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff55334-07a6-4069-a23c-4d31b39775ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete. Augmented images saved to: artifact_dataset/augmented_images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "\n",
    "# Define source and target directories\n",
    "SOURCE_DIR = \"artifact_dataset/images\"         # Contains subfolders: coin, sculpture, inscription\n",
    "AUGMENTED_DIR = \"artifact_dataset/augmented_images\"  # New folder to store augmented images\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(AUGMENTED_DIR):\n",
    "    os.makedirs(AUGMENTED_DIR)\n",
    "\n",
    "# Define your data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Loop over each subfolder (artifact type)\n",
    "for subfolder in os.listdir(SOURCE_DIR):\n",
    "    subfolder_path = os.path.join(SOURCE_DIR, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        target_subfolder = os.path.join(AUGMENTED_DIR, subfolder)\n",
    "        if not os.path.exists(target_subfolder):\n",
    "            os.makedirs(target_subfolder)\n",
    "        # Process each image in the subfolder\n",
    "        for image_file in os.listdir(subfolder_path):\n",
    "            image_path = os.path.join(subfolder_path, image_file)\n",
    "            if os.path.isfile(image_path) and image_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                # Load and preprocess image\n",
    "                img = load_img(image_path, target_size=(224, 224))\n",
    "                x = img_to_array(img)\n",
    "                x = x.reshape((1,) + x.shape)  # Shape: (1, 224, 224, 3)\n",
    "\n",
    "                # Generate 5 augmented images for each original image\n",
    "                i = 0\n",
    "                for batch in datagen.flow(\n",
    "                        x, batch_size=1):\n",
    "                    # Create a new filename that includes the original filename\n",
    "                    base, ext = os.path.splitext(image_file)\n",
    "                    new_filename = f\"{base}_aug_{i}{ext}\"\n",
    "                    new_filepath = os.path.join(target_subfolder, new_filename)\n",
    "                    array_to_img(batch[0]).save(new_filepath)\n",
    "                    i += 1\n",
    "                    if i >= 5:\n",
    "                        break\n",
    "\n",
    "print(\"Data augmentation complete. Augmented images saved to:\", AUGMENTED_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39944dc-c3a7-4bca-80b6-a04bce38a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved as cleaned_dataset.csv\n",
      "✅ Augmented dataset saved as cleaned_augmented_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = \"updated_metadata_with_history.csv\"\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Function to clean the Age column\n",
    "def process_age(age_str):\n",
    "    \"\"\"Convert 'beginning_date-end_date AD/BCE' into a single numerical value\"\"\"\n",
    "    if pd.isna(age_str):\n",
    "        return None  # Drop missing age values\n",
    "\n",
    "    try:\n",
    "        # Example: \"500-700 AD\" or \"300 BCE-100 BCE\"\n",
    "        parts = age_str.split('-')\n",
    "        start, end = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "        # Handle AD/BCE conversion\n",
    "        if \"BCE\" in start:\n",
    "            start = -int(start.replace(\"BCE\", \"\").strip())\n",
    "        else:\n",
    "            start = int(start.replace(\"AD\", \"\").strip())\n",
    "\n",
    "        if \"BCE\" in end:\n",
    "            end = -int(end.replace(\"BCE\", \"\").strip())\n",
    "        else:\n",
    "            end = int(end.replace(\"AD\", \"\").strip())\n",
    "\n",
    "        return (start + end) / 2  # Midpoint as single age value\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing age '{age_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Clean Age column\n",
    "df[\"Age\"] = df[\"Age\"].apply(process_age)\n",
    "df = df.dropna(subset=[\"Age\"])  # Drop rows with invalid age\n",
    "\n",
    "# Merge historical fields\n",
    "df[\"Historical Notes\"] = df[[\"Description\", \"Period\", \"Dynasty\", \"Object Date\", \"Culture\"]].apply(\n",
    "    lambda row: ', '.join([str(val) for val in row if pd.notna(val) and val != \"\"]), axis=1\n",
    ")\n",
    "\n",
    "# Drop original separate columns\n",
    "df = df.drop(columns=[\"Description\", \"Period\", \"Dynasty\", \"Object Date\", \"Culture\"])\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_dataset_path = \"cleaned_dataset.csv\"\n",
    "df.to_csv(cleaned_dataset_path, index=False)\n",
    "print(f\"✅ Cleaned dataset saved as {cleaned_dataset_path}\")\n",
    "\n",
    "# ----- AUGMENTATION -----\n",
    "# Define augmentations: 5 rotations (without black bars)\n",
    "augmentations = [\n",
    "    A.Rotate(limit=(90, 90), border_mode=cv2.BORDER_REFLECT_101, p=1),\n",
    "    A.Rotate(limit=(180, 180), border_mode=cv2.BORDER_REFLECT_101, p=1),\n",
    "    A.Rotate(limit=(270, 270), border_mode=cv2.BORDER_REFLECT_101, p=1),\n",
    "    A.Rotate(limit=(30, 30), border_mode=cv2.BORDER_REFLECT_101, p=1),\n",
    "    A.Rotate(limit=(-30, -30), border_mode=cv2.BORDER_REFLECT_101, p=1)\n",
    "]\n",
    "\n",
    "# Create output folder for augmented images\n",
    "augmented_dir = \"artifact_dataset/augmented_images\"\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# Augment images using Image field directly\n",
    "augmented_records = []\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = row[\"Image\"]  # Directly using the image path from metadata\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"⚠️ Missing image: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for i, aug in enumerate(augmentations):\n",
    "        augmented = aug(image=image)[\"image\"]\n",
    "        new_filename = f\"{os.path.splitext(os.path.basename(img_path))[0]}_aug{i+1}.jpg\"\n",
    "        new_path = os.path.join(augmented_dir, new_filename)\n",
    "\n",
    "        # Save augmented image\n",
    "        cv2.imwrite(new_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Append to new dataset\n",
    "        augmented_records.append({\n",
    "            \"Image\": new_path,  # Store full path of augmented image\n",
    "            \"Age\": row[\"Age\"],\n",
    "            \"Historical Notes\": row[\"Historical Notes\"]\n",
    "        })\n",
    "\n",
    "# Convert augmented data to DataFrame\n",
    "augmented_df = pd.DataFrame(augmented_records)\n",
    "augmented_dataset_path = \"cleaned_augmented_dataset.csv\"\n",
    "augmented_df.to_csv(augmented_dataset_path, index=False)\n",
    "\n",
    "print(f\"✅ Augmented dataset saved as {augmented_dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eadc8-1d2b-4786-ad0e-822617a661d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
